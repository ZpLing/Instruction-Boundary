#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Choiceå®éªŒ2.3ï¼šæ¨¡ç³Šæç¤ºå®éªŒ
å¯¹åº”TFUçš„exp_TFU_2.3.py
"""

from typing import Dict, Any, List
from ..core.api_client import ChoiceAPIClient
from ..core.evaluator import ChoiceEvaluator

class Experiment2_3:
    """å®éªŒ2.3ï¼šæ¨¡ç³Šæç¤ºå®éªŒ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.api_client = ChoiceAPIClient(config)
        self.evaluator = ChoiceEvaluator()
    
    def build_ambiguous_prompt(self, element: Dict[str, Any]) -> str:
        """æ„å»ºæ¨¡ç³Šæç¤ºçš„Choice promptï¼ˆåªä¿ç•™æœ€åŸºæœ¬ä¿¡æ¯ï¼‰"""
        
        question = element['question']
        options = element['options']
        passage = element.get('passage_text', '')
        
        # æ„å»ºé€‰é¡¹æ–‡æœ¬
        options_text = "\n".join(options)
        
        # æ„å»ºFactséƒ¨åˆ†
        facts_part = ""
        if passage and passage.strip():
            facts_part = f"Facts: {passage}\n"
        
        # æ¨¡ç³Šæç¤ºï¼ˆåªä¿ç•™æœ€åŸºæœ¬ä¿¡æ¯ï¼Œå‡å°‘å¼•å¯¼æ€§å†…å®¹ï¼‰
        prompt = f"""Question: {question}
{facts_part}Options:
{options_text}

Please respond with only the option number(s)."""

        return prompt
    
    async def run_ambiguous_experiment(self, dataset: List[Dict]) -> List[Dict]:
        """è¿è¡Œæ¨¡ç³Šæç¤ºå®éªŒ"""
        print(f"\nğŸš€ è¿è¡ŒChoiceæ¨¡ç³Šæç¤ºå®éªŒ - æ¨¡å‹: {self.config['test_model']}")
        print(f"   æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"   Judgeæ¨¡å‹: {self.config['judge_model']}")
        print(f"   æç¤ºæè¿°: æ¨¡ç³Šæç¤º - åªä¿ç•™æœ€åŸºæœ¬ä¿¡æ¯ï¼Œå‡å°‘å¼•å¯¼æ€§å†…å®¹")
        
        return await self.api_client.process_dataset(dataset, self.build_ambiguous_prompt, "ambiguous")
    
    async def run_experiment(self, dataset: List[Dict], model_name: str, dataset_name: str, 
                           output_folder: str) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        
        print("=" * 70)
        print("Choiceå®éªŒ2.3ï¼šæ¨¡ç³Šæç¤ºå®éªŒ")
        print("å®éªŒåºå·: 2.3 | å®éªŒç±»å‹: æ¨¡ç³Šæç¤ºå®éªŒ (Ambiguous Prompt)")
        print("åŸºäºchoice_exp_1.1_2.1.pyçš„ç»Ÿä¸€æ ‡å‡†")
        print("æµ‹è¯•æœ€ç®€æç¤ºï¼ˆåªä¿ç•™åŸºæœ¬ä¿¡æ¯ï¼‰å¯¹é€‰æ‹©é¢˜æ€§èƒ½çš„å½±å“")
        print("=" * 70)
        
        # è¿è¡Œæ¨¡ç³Šæç¤ºå®éªŒ
        ambiguous_results = await self.run_ambiguous_experiment(dataset)
        ambiguous_metrics = self.evaluator.calculate_choice_metrics_with_tfu_style(ambiguous_results)
        ambiguous_files = self.evaluator.save_experiment_results(
            ambiguous_results, ambiguous_metrics, model_name, dataset_name, "ambiguous", output_folder
        )
        self.evaluator.print_experiment_summary(ambiguous_metrics, "æ¨¡ç³Šæç¤º")
        
        return {
            "ambiguous_results": ambiguous_results,
            "ambiguous_metrics": ambiguous_metrics,
            "ambiguous_files": ambiguous_files
        }
